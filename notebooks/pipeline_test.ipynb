{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf559765-3018-41da-9165-668613093798",
   "metadata": {},
   "source": [
    "# Testing The Pipeline üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3044f4-56e3-409f-bd04-f9e953d54cfa",
   "metadata": {},
   "source": [
    "### üìÇ Download Testing Dataset\n",
    "In this step, we are downloading the testing dataset from GitHub. This dataset will be used to evaluate the pipeline's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1989cf-570a-4ab7-8478-6672d2224fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/samryan18/chess-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911d5cd-8173-4f1f-aceb-d4a9feb9d0dd",
   "metadata": {},
   "source": [
    "### üìÅ Organizing the Dataset\n",
    "This command moves the downloaded dataset from its original location to the workspace/tests directory for easier access and organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697c50d-8288-45cc-9e3c-0f85c1580261",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv chess-dataset/labeled_originals /workspace/tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0a1f9-03a0-4c1e-9df4-26cde187a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r chess-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189917bc-869b-44fe-a842-8ca0c085b31c",
   "metadata": {},
   "source": [
    "### üì¶ Installing Dependencies\n",
    "This step installs all the necessary Python libraries required for the pipeline. These libraries include tools for image processing, numerical operations, plotting, and chess-specific functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f099377-f91d-43e0-adc1-02323ae6f65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless numpy pillow shapely ultralytics python-chess cairosvg matplotlib python-dotenv svglib reportlab python-Levenshtein numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb4d3e-5077-4fc3-b20a-b8878735ea91",
   "metadata": {},
   "source": [
    "### üìö Importing Required Modules and Classes\n",
    "In this step, we are importing essential Python modules and custom classes that will be used throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39f8358e-1d30-4f53-9401-52d368f040a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import sys\n",
    "from Levenshtein import ratio\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522edc8d-1e29-4637-acfd-9052c0dcbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.shared import CornerDetector, PerspectiveTransformer, GridCalculator, ChessPieceMapper, FENConverter, ImageGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b89397-8625-4d58-bb14-3905f2f330d6",
   "metadata": {},
   "source": [
    "### üîç Comparing Processed Image with the Original\n",
    "This function compares a processed chessboard image with its original by analyzing and transforming it into a format (FEN notation) that can be compared for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d42c407-ec5b-49db-8040-4a5d8575ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_image_with_original(image_path):\n",
    "    original_image = cv2.imread(image_path)\n",
    "    corners = CornerDetector.detect_corners(original_image)\n",
    "    transformed_image = PerspectiveTransformer.four_point_transform(image_path, corners)\n",
    "    ptsT, ptsL = GridCalculator.plot_grid_on_transformed_image(transformed_image)\n",
    "    detections, boxes = ChessPieceMapper.chess_pieces_detector(transformed_image)\n",
    "    predicted_fen = FENConverter.generate_fen(ptsT, ptsL, detections, boxes)\n",
    "\n",
    "    real_fen = \"/\".join(image_path.split(\"/\")[-1].split(\".\")[0].split(\"-\"))\n",
    "\n",
    "    similarity = ratio(real_fen, predicted_fen)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63015767-c4b4-4955-ae5c-4677e586d667",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Loading Test Images\n",
    "This step retrieves all test images from the **./tests** directory to prepare them for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09cc8ed-d11b-4293-b788-8a21d5d42bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the testing image: 500\n"
     ]
    }
   ],
   "source": [
    "test_images = glob(\"./tests/*.JPG\", recursive=True)\n",
    "print(\"Number of the testing image:\", len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ceedbf-d702-4c23-9193-617614aaa0f1",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Evaluating Test Images\n",
    "In this step, we process each test image to evaluate its similarity to the original FEN notation. The results are stored in a list for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30392f46-5146-4db0-b901-e32a7f0d8409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [24:34<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for image in tqdm(test_images):\n",
    "    try:\n",
    "        results.append(compare_image_with_original(image))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3c162-cc84-4406-94bd-ca7e4cb447f0",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Evaluation Metrics\n",
    "\n",
    "In this step, we analyze the performance of the chessboard detection and FEN conversion system using several evaluation metrics. These metrics provide insights into the effectiveness and accuracy of the approach, helping to identify areas of strength and potential improvement.\n",
    "\n",
    "#### **1. Total Test Images**\n",
    "This metric represents the total number of images in the testing dataset. It gives an overview of the dataset size used for evaluation and forms the baseline for all other metrics.\n",
    "\n",
    "#### **2. Processed Images**\n",
    "The number of test images successfully processed by the system. A higher number indicates robustness and fewer errors during execution.\n",
    "\n",
    "#### **3. Failed Images**\n",
    "The count of images that could not be processed due to errors or exceptions. This metric is crucial for understanding system reliability and stability.\n",
    "\n",
    "#### **4. Accuracy (Mean Similarity)**\n",
    "The average similarity score between the predicted FEN notation and the original FEN notation across all processed images. This is the primary indicator of the system‚Äôs overall accuracy.\n",
    "\n",
    "#### **5. Minimum Similarity**\n",
    "The lowest similarity score achieved in the evaluation. This metric identifies outliers or instances where the system struggled the most.\n",
    "\n",
    "#### **6. Maximum Similarity**\n",
    "The highest similarity score achieved in the evaluation. It highlights the system's best performance and serves as a benchmark for improvement.\n",
    "\n",
    "#### **7. Median Similarity**\n",
    "The middle value of similarity scores, providing a robust measure of central tendency, especially useful in datasets with outliers.\n",
    "\n",
    "#### **8. Standard Deviation**\n",
    "This metric measures the spread or variability of the similarity scores. A lower standard deviation indicates consistent performance across the dataset, while a higher value suggests variability.\n",
    "\n",
    "By analyzing these metrics, we gain a comprehensive understanding of the system's performance and identify areas that may require optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f61bccdd-5ecd-4c96-b67b-d019b2f32ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric              Value          \n",
      "-----------------------------------\n",
      "Total Test Images   500            \n",
      "Processed Images    448            \n",
      "Failed Images       52             \n",
      "Accuracy (Mean Sim.)         81.93%\n",
      "Minimum Similarity            0.40\n",
      "Maximum Similarity            1.00\n",
      "Median Similarity             0.83\n",
      "Standard Deviation            0.09\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    min_similarity = np.min(results)\n",
    "    max_similarity = np.max(results)\n",
    "    mean_similarity = np.mean(results)\n",
    "    median_similarity = np.median(results)\n",
    "    std_deviation = np.std(results)\n",
    "    total_images = len(results)\n",
    "    failed_images = len(test_images) - total_images\n",
    "\n",
    "    accuracy = mean_similarity * 100\n",
    "\n",
    "    print(f\"{'Metric':<20}{'Value':<15}\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"{'Total Test Images':<20}{len(test_images):<15}\")\n",
    "    print(f\"{'Processed Images':<20}{total_images:<15}\")\n",
    "    print(f\"{'Failed Images':<20}{failed_images:<15}\")\n",
    "    print(f\"{'Accuracy (Mean Sim.)':<20}{accuracy:>14.2f}%\")\n",
    "    print(f\"{'Minimum Similarity':<20}{min_similarity:>14.2f}\")\n",
    "    print(f\"{'Maximum Similarity':<20}{max_similarity:>14.2f}\")\n",
    "    print(f\"{'Median Similarity':<20}{median_similarity:>14.2f}\")\n",
    "    print(f\"{'Standard Deviation':<20}{std_deviation:>14.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo results to analyze. Please check your data or debugging logs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce5aa1-d68e-4172-ad86-da3298d7afde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
